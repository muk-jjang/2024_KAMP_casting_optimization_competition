{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from casting.configuration import paths, columns, ranges, params\n",
    "from casting.preprocessing import (calculate_defect_rate, \n",
    "                                   drop_null, \n",
    "                                   remove_extreme_outliers, \n",
    "                                   split_by_dbscan,\n",
    "                                   remove_outlier,\n",
    "                                   save_scaler,\n",
    "                                   save_label_encoding)\n",
    "from casting.utils import load_data\n",
    "\n",
    "\n",
    "from casting.trainner import train_xgboost, train_lightgbm, train_extra_trees\n",
    "from casting.trainner import train_tabnet, train_FTT\n",
    "\n",
    "from casting.model.pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_origin = pd.read_csv(paths.origin_path, encoding = 'euc-kr')\n",
    "data = data_origin[columns.use_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## null 값 제외\n",
    "data = drop_null(data).reset_index(drop=True)\n",
    "## 이상치 제거\n",
    "data = remove_outlier(data)\n",
    "\n",
    "\n",
    "if params.model_name == 'FTT':\n",
    "    ## 스케일러 생성\n",
    "    save_scaler(data, \n",
    "                columns.numeric_columns, \n",
    "                columns.target_column,\n",
    "                paths.X_scaler_path,\n",
    "                paths.y_scaler_path\n",
    "                )\n",
    "    ## 카테고리 컬럼 처리를 위한 라벨 인코딩\n",
    "    save_label_encoding(data, columns.category_columns, paths.label_encoding_path)\n",
    "\n",
    "    split_by_dbscan(data, 'casting/data/scaled_data/')\n",
    "else :\n",
    "    ## 데이터 분리\n",
    "    split_by_dbscan(data, 'casting/data/processed_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "train, valid, test = load_data(params.model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_FTT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Git_hub_repo/KAMP_casting_optimization_competition/casting_optimization/casting/trainner/_train_DL_model.py:99\u001b[0m, in \u001b[0;36mtrain_FTT\u001b[0;34m(train, valid)\u001b[0m\n\u001b[1;32m     96\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     97\u001b[0m x_categ, x_numer, y \u001b[38;5;241m=\u001b[39m x_categ\u001b[38;5;241m.\u001b[39mto(device), x_numer\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 99\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_categ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_numer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m    101\u001b[0m loss_e \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/saas-control-job/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/saas-control-job/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Git_hub_repo/KAMP_casting_optimization_competition/casting_optimization/casting/model/ft_transformer.py:212\u001b[0m, in \u001b[0;36mFTTransformer.forward\u001b[0;34m(self, x_categ, x_numer, return_attn)\u001b[0m\n\u001b[1;32m    208\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((cls_tokens, x), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# attend\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m x, attns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_attn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# get cls token\u001b[39;00m\n\u001b[1;32m    216\u001b[0m x \u001b[38;5;241m=\u001b[39m x[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/saas-control-job/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/saas-control-job/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Git_hub_repo/KAMP_casting_optimization_competition/casting_optimization/casting/model/ft_transformer.py:92\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, return_attn)\u001b[0m\n\u001b[1;32m     89\u001b[0m     post_softmax_attns\u001b[38;5;241m.\u001b[39mappend(post_softmax_attn)\n\u001b[1;32m     91\u001b[0m     x \u001b[38;5;241m=\u001b[39m attn_out \u001b[38;5;241m+\u001b[39m x\n\u001b[0;32m---> 92\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m x\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_attn:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/saas-control-job/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/saas-control-job/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/saas-control-job/lib/python3.8/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/saas-control-job/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/saas-control-job/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/saas-control-job/lib/python3.8/site-packages/torch/nn/modules/dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/saas-control-job/lib/python3.8/site-packages/torch/nn/functional.py:1266\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = train_extra_trees(train, valid)\n",
    "# model = train_lightgbm(X_train, X_valid, y_train, y_valid)\n",
    "# model = train_xgboost(train, valid)\n",
    "# model = train_tabnet(X_train, X_valid, y_train, y_valid)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "model = train_FTT(train, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# 혼동 행렬 계산\n",
    "\n",
    "\n",
    "X_test, y_test = test[columns.input_columns], test[columns.target_column]\n",
    "\n",
    "y_pred = model.predict(X_test.values)\n",
    "test_cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 혼동 행렬 계산\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 혼동 행렬 시각화\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8904\n",
      "accuracy_score: 0.9913\n",
      "precision_score: 0.9363\n",
      "recall_score: 0.8489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# 점수 계산\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'accuracy_score: {acc:.4f}')\n",
    "\n",
    "ps = precision_score(y_test, y_pred)\n",
    "print(f'precision_score: {ps:.4f}')\n",
    "\n",
    "rs = recall_score(y_test, y_pred)\n",
    "print(f'recall_score: {rs:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FTT Modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
